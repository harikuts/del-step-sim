{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gossip Learning Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Network Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n",
    "import traceback\n",
    "\n",
    "# Packet class\n",
    "class Packet:\n",
    "    def __init__(self, src, dest, data):\n",
    "        self.src = src\n",
    "        self.dest = dest\n",
    "        self.data = data\n",
    "    def __str__(self):\n",
    "        return \"src=\" + self.src + \",dest=\" + self.dest + \",data=\" + str(self.data)\n",
    "\n",
    "class DummyNet:\n",
    "    def __init__(self, address, neighbor_addrs = []):\n",
    "        self.ip = address\n",
    "        self.neighbor_addrs = neighbor_addrs\n",
    "        self.outbox = []\n",
    "        self.receiver = []\n",
    "        self.inbox = []\n",
    "        self.active = True\n",
    "        \n",
    "    # Second stage initialization to build the 'network connections'.\n",
    "    def init_network(self, registry):\n",
    "        # Build neighbors\n",
    "        self.build_neighbors(registry)\n",
    "        # Init sender and receiver processes\n",
    "        self.init_sender()\n",
    "        self.init_receiver()\n",
    "        \n",
    "    # Used to set active flag such that send/receive processes terminate.\n",
    "    def kill(self):\n",
    "        self.active = False\n",
    "        \n",
    "    # Networ reporting function.\n",
    "    def print_(self, message):\n",
    "        # Network level print messaging\n",
    "        output = \"NET::[\" + str(self.ip) + \"]::\"\n",
    "        try:\n",
    "            output = output + str(message)\n",
    "        except:\n",
    "            output = output + \"Message not printable.\"\n",
    "        print(output)\n",
    "        \n",
    "    # Given registry, builds neighbor dictionary.\n",
    "    def build_neighbors(self, registry):\n",
    "        # The registry is built as a dictionary with key IP address an entry DummyNet object\n",
    "        self.neighbors = {}\n",
    "        for addr in self.neighbor_addrs:\n",
    "            self.neighbors[addr] = registry[addr]\n",
    "    \n",
    "    # Starts sender service.\n",
    "    def init_sender(self):\n",
    "        threading.Thread(target=self.__send, args=()).start()\n",
    "        pass\n",
    "    \n",
    "    # Starts receiver service.\n",
    "    def init_receiver(self):\n",
    "        threading.Thread(target=self.__receive, args=()).start()\n",
    "        pass\n",
    "    \n",
    "    # Network layer send function.\n",
    "    def __send(self):\n",
    "        while self.active:\n",
    "            # Send packet, if failed, print exception.\n",
    "            try:\n",
    "                if len(self.outbox):\n",
    "                    packet = self.outbox.pop(0)\n",
    "                    self.neighbors[packet.dest].receiver.append(packet)\n",
    "                    self.print_(\"Sent: \" + str(packet))\n",
    "            except Exception as e:\n",
    "                self.print_(\"Sending error has occurred.\")\n",
    "                traceback.print_exc()\n",
    "    \n",
    "    # Receiving/processing function.\n",
    "    def __receive(self):\n",
    "        while self.active:\n",
    "            try:\n",
    "                if len(self.receiver):\n",
    "                    packet = self.receiver.pop(0)\n",
    "                    self.inbox.append(packet)\n",
    "                    self.print_(\"Received: \" + str(packet))\n",
    "            except Exception as e:\n",
    "                self.print_(\"Receiving error has occurred.\")\n",
    "                traceback.print_exc()\n",
    "        pass\n",
    "    \n",
    "    # Application layer send function.\n",
    "    def send(self, payload, address):\n",
    "        # Create packet\n",
    "        packet = Packet(self.ip, address, payload)\n",
    "        # Load packet into outbox\n",
    "        self.outbox.append(packet)\n",
    "        \n",
    "    # Application layer receive function, gets from inbox buffer.\n",
    "    def receive(self):\n",
    "        # If buffer is not empty, return packet, else return None.\n",
    "        try:\n",
    "            return self.inbox.pop(0)\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "X_INDEX = 1\n",
    "Y_INDEX = 2\n",
    "DATA_INDEX = 0\n",
    "\n",
    "NUM_EPOCHS = 2\n",
    "\n",
    "class Model:\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.model = self.create_model()\n",
    "        self.sharing_model = None\n",
    "        \n",
    "    def step(self):\n",
    "        history = self.model.fit(self.data[X_INDEX], self.data[Y_INDEX], epochs=NUM_EPOCHS)\n",
    "        self.sharing_model = (self.data[DATA_INDEX], self.model.get_weights)\n",
    "        \n",
    "    # List of tuples of [data size, weights] from other nodes\n",
    "    def aggregate(self, recv_list):\n",
    "        pass\n",
    "    \n",
    "    # Use this function to select one of the model creation functions\n",
    "    def create_model(self):\n",
    "        return self.standardNN()\n",
    "\n",
    "    # Standard Neural Network\n",
    "    def standardNN(self):\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "            tf.keras.layers.Dense(32, activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Dense(10)\n",
    "        ])\n",
    "        loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "        model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "class ModelIncubator:\n",
    "    def __init__(self, data_ratios):\n",
    "        self.x_train, self.x_test, self.y_train, self.y_test = self.get_dataset()\n",
    "        self.data_shares = self.rsplit(self.x_train, self.y_train, nonIID=True, ratios=data_ratios)\n",
    "        print(\"Model incubator has been generated.\")\n",
    "        \n",
    "    # Use this function to select one of the dataset grab functions\n",
    "    def get_dataset(self):\n",
    "        return self.get_mnist()\n",
    "\n",
    "    # MNIST Dataset\n",
    "    def get_mnist(self):\n",
    "        # Import MNIST data\n",
    "        print (\"\\nDownloading MNIST data...\")\n",
    "        mnist = tf.keras.datasets.mnist\n",
    "        # Load data into trains\n",
    "        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "        x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "        return x_train, x_test, y_train, y_test\n",
    "\n",
    "    # To split the data\n",
    "    def rsplit(self, x_train, y_train, nonIID=False, ratios=None):\n",
    "        # Splitting the dataset for different clients\n",
    "        print (\"\\nSplitting data into different clients...\")\n",
    "        if True:\n",
    "            print (\"\\tAssigning ranges of data...\")\n",
    "            accumulations = np.array([sum(ratios[0:i+1]) for i in range(len(ratios))])\n",
    "            print(accumulations)\n",
    "            markers = accumulations * len(x_train)\n",
    "            markers = [int(marker) for marker in markers]\n",
    "            print(markers)\n",
    "        else:\n",
    "            print (\"\\tUniformly assigning ranges of data\")\n",
    "            # markers = [1/num_clients * (n+1) for n in range(num_clients)]\n",
    "        # Storing each subset of data in a client\n",
    "        print (\"\\tStoring subsets of data into each client...\")\n",
    "        dataSplits = []\n",
    "        for j in range(len(markers)):\n",
    "            x_data = x_train[(markers[j-1] if j > 0 else 0):markers[j]]\n",
    "            y_data = y_train[(markers[j-1] if j > 0 else 0):markers[j]]\n",
    "            data_size = len(x_data)\n",
    "            dataSplits.append((data_size, x_data, y_data))\n",
    "        return dataSplits\n",
    "    \n",
    "# mi = ModelIncubator([0.5, 0.25, 0.25])\n",
    "# m = Model(mi.data_shares[0])\n",
    "# m.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import secrets\n",
    "\n",
    "# A single record.\n",
    "class Record:\n",
    "    def __init__(self, ip, weights, expiry):\n",
    "        self.ip = ip\n",
    "        self.weights = weights\n",
    "        self.expiry = expiry\n",
    "    def step(self, s=1):\n",
    "        self.expiry -= 1\n",
    "        if self.expiry <= 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "# Holds and manages records and requests.\n",
    "class GuestBook:\n",
    "    def __init__(self):\n",
    "        self.records = {}\n",
    "    def encounter(self, ip, weights, expiry):\n",
    "        self.records[ip] = Record(ip, weights, expiry)\n",
    "    def step(self):\n",
    "        # Increment another step and reduce expirations across records.\n",
    "        for ip in self.records.keys():\n",
    "            # If incremental step results in expiration, remove record.\n",
    "            if self.records[ip].step():\n",
    "                expunged = self.records.pop(ip)\n",
    "                \n",
    "\n",
    "class Client:\n",
    "    def __init__(self, netNode=None, ip=None, neighbor_addrs=None, model=None ):\n",
    "        if netNode is not None:\n",
    "            self.net = netNode\n",
    "        else:\n",
    "            self.net = DummyNet(ip, neighbor_addrs)\n",
    "        self.model_message = \"hi it's me from \" + self.net.ip\n",
    "        self.model_ready = False\n",
    "        # Set active flag\n",
    "        self.active = True\n",
    "        \n",
    "        # Model with data\n",
    "        self.model = model\n",
    "            \n",
    "    # Client reporting function\n",
    "    def print_(self, message):\n",
    "        # Client level print messaging\n",
    "        output = \"CLIENT::[\" + str(self.net.ip) + \"]::\"\n",
    "        try:\n",
    "            output = output + str(message)\n",
    "        except:\n",
    "            output = output + \"Message not printable.\"\n",
    "        print(output)\n",
    "        \n",
    "    # Main run process as a state machine.\n",
    "    def process(self):\n",
    "        # While active, run\n",
    "        # Check inbox\n",
    "        packet = self.net.receive()\n",
    "        if packet is not None:\n",
    "            self.model_ready = False\n",
    "            self.print_(\"Processing model from \" + str(packet.src))\n",
    "            self.print_(\"Aggregating model with new input.\")\n",
    "        else:\n",
    "            # Train the model on local data\n",
    "            self.print_(\"Training model.\")\n",
    "            self.model.step()\n",
    "            self.model_ready = True            \n",
    "    \n",
    "    # Lowest level client transmission function.\n",
    "    def transmit(self, payload, target_addr):\n",
    "        self.net.send(payload, target_addr)\n",
    "        \n",
    "    # Model transfer function.\n",
    "    def transmit_model(self, recipient):\n",
    "        # Select recipient\n",
    "        # Transmit model to recipient\n",
    "        if self.model_ready:\n",
    "            self.transmit(self.model_message, recipient)\n",
    "            self.print_(\"Transmitting model to \" + recipient)\n",
    "        else:\n",
    "            self.print_(\"Model still processing.\")\n",
    "    # Select random recipient.\n",
    "    def select_random_recv(self):\n",
    "        return secrets.choice(list(self.net.neighbors.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "class Console:\n",
    "    def __init__(self, clientDict):\n",
    "        self.clients = clientDict\n",
    "        pass\n",
    "    def run(self):\n",
    "        while True:\n",
    "            try:\n",
    "                cmd = input(\">>\").strip().split(\" \")\n",
    "                cmd = [c.strip() for c in cmd]\n",
    "                if cmd[0] == \"exit\":\n",
    "                    break\n",
    "                elif cmd[0] == \"step\":\n",
    "                    if len(cmd) == 1:\n",
    "                        self.step()\n",
    "                    else:\n",
    "                        self.istep(cmd[1])\n",
    "                elif cmd[0] == \"neighborhood\":\n",
    "                    print (self.get_all_addrs())\n",
    "                elif cmd[0] == \"exchange\":\n",
    "                    self.exchange(cmd[1], cmd[2])\n",
    "                elif cmd[0] == \"flood\":\n",
    "                    if len(cmd) == 1:\n",
    "                        self.floodall()  \n",
    "                    else:\n",
    "                        self.flood(cmd[1])\n",
    "                else:\n",
    "                    print(\"Command does not exist.\")\n",
    "            except Exception as e:\n",
    "                print(\"Command did not work. Check arguments.\")\n",
    "                print(e)\n",
    "    # SYSTEM LEVEL COMMANDS\n",
    "    def get_all_addrs(self):\n",
    "        return str(list(self.clients.keys()))\n",
    "    def step(self):\n",
    "        for client in self.clients.values():\n",
    "            client.process()\n",
    "    def floodall(self):\n",
    "        for client in self.clients.values():\n",
    "            for neighbor in client.net.neighbors.keys():\n",
    "                client.transmit_model(neighbor)\n",
    "    # INTERNODE LEVEL COMMANDS\n",
    "    def exchange(self, ip1, ip2):\n",
    "        self.clients[ip1].transmit_model(ip2)\n",
    "        self.clients[ip2].transmit_model(ip1)\n",
    "    def flood(self, ip):\n",
    "        for neighbor in self.clients[ip].net.neighbors.keys():\n",
    "            self.clients[ip].transmit_model(neighbor)\n",
    "    # NODE LEVEL COMMANDS\n",
    "    def istep(self, ip):\n",
    "        self.clients[ip].process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created network graph.\n",
      "Registered nodes in network graph.\n",
      "\n",
      "Downloading MNIST data...\n",
      "\n",
      "Splitting data into different clients...\n",
      "\tAssigning ranges of data...\n",
      "[0.5 0.8 1. ]\n",
      "[30000, 48000, 60000]\n",
      "\tStoring subsets of data into each client...\n",
      "Model incubator has been generated.\n",
      "Creating client  0  with IP  10.0.0.1 .\n",
      "Creating client  1  with IP  10.0.0.2 .\n",
      "Creating client  2  with IP  10.0.0.3 .\n",
      "Clients created and linked to nodes.\n",
      ">>step\n",
      "CLIENT::[10.0.0.1]::Training model.\n",
      "Train on 30000 samples\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - ETA: 0s - loss: 0.5979 - accuracy: 0.827957     ETA: 31:19:03 - loss: 2.2508 - accuracy: 0.14 - ETA: 20:56:58 - loss: 2.2782 - accuracy: 0.13 - ETA: 15:47:24 - loss: 2.2753 - accu - ETA: 5:02:07 - loss: 2.1936 - accuracy - ETA: 3:12:57 - loss - ETA: 1:31:39 - loss: 1.8367 - accuracy: 0.418 - ETA: 1:30:03 - loss: 1.8276 - accuracy:  - ETA: 1:22:04 - loss: 1.7666 - accuracy: 0. - ETA: 1:17:27 - loss: 1.7303 - accur - ETA: 1:07:07 - loss: 1.6551 - accu - ETA: 58:14 - loss: 1.5730 -  - ETA: 50:04 - loss: 1.4691 - accuracy: 0. - ETA: 48:22 - loss: 1.4442 - accuracy: 0.564 - ETA: 48:00 - loss: 1.4365 - accuracy: 0.56 - ETA: 47:24 - loss: 1.4272 - accuracy: 0.570 - ETA: 47:06 - loss: 1.4228 - accuracy: 0.5 - ET - ETA: 35:19 - loss: 1.2468 - accuracy: 0.6 - ETA: 34:47 - loss: 1.2363 - accuracy: - ETA: - ETA - ETA: 24:56 - loss: 1.0224 - accuracy: - ETA: 24:21 - loss: 1.0122 - accuracy:  - ETA: 23:58 - loss: 1.0029 - - ETA: 22:30 - loss: 0.9750 - accura - ETA: 21:49 - loss: 0.9605 - accuracy: 0.718 - ETA: 21:48 - loss: 0.9593 - accuracy: 0 - ETA: 21:40 - loss: 0.9528 - accuracy: 0.721 - ETA: 21:38 - loss: 0.9510 - accuracy: 0.722 - ETA: 21:35 - loss: 0.9488 - accuracy: 0.7 - ETA: 21:21 - loss: 0.9442 -  - ETA: 20:22 - loss: 0.9242 - accuracy: 0.73 - ETA: 20:19 - loss: 0.9218 - accu - ETA: 19:37 - loss: 0.9057 - accuracy:  - ETA: 19:22 - loss: 0.9004 - accu - ETA: 18:45 - loss: 0.8873 - accuracy: - ETA: 18:24 - loss: 0.8804 - accuracy: 0 - ETA: 18:07 - loss - ETA: 16:48 - l - ETA: 15:28 - loss: 0.8195 -  - ETA: 13:04 - loss: 0.7768 - accuracy:  - ETA: 12:54 - loss: 0.7728 - accuracy: 0.77 - ETA: 12:50 - loss: 0.7717 - accuracy: 0.777 - ETA: 12:47 - loss: 0.7705 - accura - ETA: 12:24 - loss: 0.7629 - accuracy: 0.779 - ETA: 12:21 - loss: 0.7620 - accuracy: 0.7 - ETA: 12:17 - loss: 0.7596 - accuracy: 0.780 - ETA: 12:15 - loss: 0.7588 - ac - ETA: 11:43 - loss: 0.7498 - accuracy: 0 - ETA: 11:33 - loss: 0.7471 - accurac - ETA: 11:14 - loss: 0.7408 - accuracy: 0.787 - ETA: 11:12 - loss: 0.7402 - accuracy: 0.78 - ETA: 11:08 - loss: 0.7386 - accuracy - ETA: 10:53 - loss: 0.7350 - accuracy: 0.7 - ETA: 10:46 - loss: 0.7335 - accuracy: 0. - ETA: 10:38 - loss: 0.7315 - accuracy: - ETA: 10:25 - loss: 0.7277 - accuracy: 0.7 - ETA: 10:19 - loss: 0.7266 - accuracy: 0. - ETA: 9:22 - loss: 0.7130  - ETA: 9:03 - loss: 0.7080 - ac - ETA: 8:51 - loss: 0.7048 - accuracy:  - ETA: 8:45 - loss: 0.7042 - accura - ETA: 8:36 - loss: 0.7019 - accuracy - ETA: 8:28 - loss: 0.7002  - ETA: 8:12 - loss: 0.6974 - accura - ETA: 8:04 - loss: 0.6950 - accura - ETA: 7:56 - loss: - ETA: 7:32 - loss: 0 - ETA: 7:11 - loss: 0.6825  - ETA: 6:56 - loss: 0 - ETA: 6:36 - loss: 0.6737 - accuracy: 0. - ETA: 6:32 - loss: 0.6732 - ac - ETA: 6:20 - loss: 0.6 - ETA: 6:03 - loss: 0.6666 - accura - ETA: 5:54 - loss: 0.665 - ETA: 5:01 - loss: 0.6534 - accuracy: 0. - ETA: 4:58 - loss: 0.652 - ETA: 4:40 - loss: 0.6499 -  - ETA: 4:28 - loss: 0.6473 - accuracy: 0. - ETA: 4:24 - loss: 0.6462 - accuracy: 0.81 - ETA: 4:23 - loss: 0.6461 - accu - ETA: 3:38 - loss: 0.6370 - accuracy - ETA: 3:33 - loss: 0.6361 - accura - ETA: 3:24 - - ETA: 1:18 - loss: 0.6112 - accuracy - ETA: 1:13 - loss: 0.609 - ETA: 58s - loss: 0.6068 - accuracy: - ETA: 47s - loss: 0.6054 - accuracy: - ETA: 37s - loss: 0.6028 - accuracy: - ETA: 27s - loss: 0.6015 - accuracy: 0 - ETA: 20s - loss: 0.6003 - accuracy: - ETA: 10s - loss: 0.5993 - accuracy: 0.827 - ETA: 9s - loss: 0.5991 - acc - 1323s 44ms/sample - loss: 0.5978 - accuracy: 0.8279\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 1089s 36ms/sample - loss: 0.3300 - accuracy: 0.903813:45 - loss: 0.3826 - accurac - ETA: 19:00 - loss: 0.3650 - accur - ETA: 17:26 - loss: 0.3707 - accuracy: 0.88 - ETA: 17:32 - loss: 0.3786 - accuracy:  - ETA: 17:38 - loss: 0.3850 - accuracy: 0.88 - ETA: 17:57 - loss: 0.3853 - accuracy: 0.8 - ETA: 18:15 - loss: 0.3918 - accuracy - ETA: 18:18 - loss: 0.3878 - ETA: 18:30 - loss: 0.3861 - accuracy - ETA: 18:33 - loss: 0.3935 - accuracy: 0. - ETA: 18:35 - loss: 0.3897 - accu - ETA: 18:21 - loss: 0.3780 - accuracy - ETA: 18:01 - loss: 0.3753 - accuracy - ETA: 18:01 - loss: 0.3780 - accur - ETA: 17:33 - loss: 0.3797 - accuracy: - ETA: 17:21 - loss: 0.3809 - accuracy: 0.8 - ETA: 17:11 - loss: 0.3780 - accur - ETA: 16:32 - loss: 0.3772 - accuracy: 0.88 - ETA: 16:29 - loss: 0.3762 - acc - ETA: 15:54 - loss: 0.3753 - accuracy: 0.88 - ETA: 15:50 - loss: 0.3758 - accuracy - ETA: 15:34 - loss: 0.3746 -  - ETA: 15:11 - loss: 0.3677 - accuracy: 0.8 - ETA: 15:13 - loss: 0.3664 - accuracy: 0.8 - ETA: 15:11 - loss: 0.3711 - accuracy: 0 - ETA: 15:09 - loss: 0.3700 - accuracy - ETA: 14:54 - loss: 0.3701 - accurac - ETA: 14:38 - loss: 0.3697 - accuracy: 0.88 - ETA: 14:36 - loss: 0.3703 - accuracy: - ETA: 14:28 - loss: 0.3689 - accuracy: 0.8 - ETA: 14:26 - loss: 0.3690 - accuracy: 0 - ETA: 14:23 - loss: 0.3698 - accur - ETA: 14:16 - loss: 0.3 - ETA: 13:51 - loss: 0.3649 - accuracy: 0.89 - ETA: 13:48 - loss: 0.3646 - accuracy: 0.89 - ETA: 13:47 - loss: 0.3660 - ac - ETA: 13:34 - loss - ETA: 12:56 - loss: 0.3632 - accuracy: 0.891 - ETA: 12:56 - loss: 0.363 - ETA: 12:27 - loss: 0.3634  - ETA: 11:58 - loss: 0.3608 - accuracy: 0.892 - ETA: 11:58 - loss: 0.3607 - accuracy: - ETA: 11:46 - loss: 0.3599 - accuracy: 0.893 - ETA: 11:44 - loss: 0.3596 - ETA: 11:09 - loss: 0.3576 - accura - ETA: 10:50 - loss: 0.3564 - a - ETA: 10:27 - loss: 0.3555 - accuracy: 0.895 - ETA: 10:28 - loss: 0.3549 - accura - ETA: 10:15 - loss: 0.3536 - accuracy - ETA: 10:14 - loss: 0.3527 - accuracy: 0.8 - ETA: 10:15 - loss: 0.3527 - accuracy -  - ETA: 9:30 - loss: - ETA: 9:10 - loss: 0.3465 - accuracy - ETA: 9:04 - ETA: 8:39 - loss: 0.3450 - accuracy: 0.89 - ETA: 8:39 - loss: 0.344 - ETA: 8:27 - loss: 0.344 - ETA: 8: - ETA: 6:32 - loss: 0.3426  - ETA: 6:23 - loss: 0.3430 - accuracy: 0.89 - ETA: 6:22 - loss: 0.3426 - accuracy: 0.89 - ETA: 6:21 - loss: 0.3429 - accu - ETA: 6:14 - loss: 0.3424 - accuracy - ETA: 6:10 - loss: 0.3436 - accuracy - ETA: 6:06 - los - ETA: 5:22 - loss: 0.3425 - accuracy:  - ETA: 5:20 - loss: 0.3421 - accuracy:  - - ETA: 4:52 - loss: 0.3406 - accu - ETA: 4:45 - loss: 0.3400 - accuracy: 0.89 - ETA - ETA: 4:23 - loss: 0.3386 - accuracy - ETA: 4: - ETA: 3:58 - loss: - ETA: 3:44 - loss: 0.3351 - accuracy: 0.90 - ETA: 3:17 - loss: 0.3348 - accuracy: 0.90 - ETA: 3:16 - loss: 0.3347 - ac - ETA: 3:08 - loss: 0.3340 - accuracy:  - ETA: 3: - ETA: 2:43 - loss: 0.3344 - accuracy: 0. - ETA: 2:15 - loss: 0.3336 - accura - ETA: 2:10 - loss: 0.3341 -  - ETA:  - ETA: 1:39 - loss: 0 - ETA: 1:26 - loss: 0.3 - ETA: 1:13 - - ETA: 50s - loss: 0.3322 - accuracy: - ETA: 42s - loss: 0.3312 - accuracy: 0.9 - ETA: 38s - loss: 0.3310 - accuracy: 0. - ETA: 34s - loss: 0.3304 - accuracy: 0.90 - ETA: \n",
      "CLIENT::[10.0.0.2]::Training model.\n",
      "Train on 18000 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 914s 51ms/sample - loss: 0.7122 - accuracy: 0.7897A: 1:03:40 - loss: 1.8531 - accuracy - ETA: 54:22 - loss: 1.7742 - - ETA: 41:22 - loss: 1.6190 - accurac - ETA: 37:02 - loss: 1.5442 - accuracy: 0. - ETA: 35:31 - loss: 1.5152 - accuracy: 0.54 - ETA: 34:45 - loss: 1.4948 - - ETA: 29:07 - loss: 1.3947 - accuracy: 0.5 - ETA: 28:24 - loss: 1.3822 - accuracy: 0.580 - ETA: 28:12 - loss: 1.3762 - accuracy: 0.5 - ETA: 27:32 - loss: 1.3631 - accu - ETA: 24:47 - loss: 1.3106 - accur - ETA: 22:58 - loss: 1.2655 - accuracy - ETA: 21:46 - loss: 1.2326 - accuracy: 0.6 - ETA: 21:20 - loss: 1.2240 - accuracy:  - ETA: 20:34 - loss: 1.2016 - accuracy: 0.637 - ETA: 20:26 - loss: 1.1994 - accuracy: 0.638 - ETA: 20:19 - loss: 1.1962 - accuracy: - ETA: 19:19 - loss: 1.1752 - accuracy: 0. - ETA: 18:51 - loss: 1.1641 - accuracy: 0.648 - ETA: 18:45 - loss: 1.1614 - accuracy: 0.6 - ETA: 18:27 - loss: 1.1558 - ETA: 16:29 - loss: 1.1047 - accuracy: 0.666 - ETA: 16:25 - loss: 1.1033 - accuracy: 0.66 - ETA: 16:15 - loss: 1.0992 - accuracy: 0.667 - ETA: 16:09 - loss: 1.0965 - accuracy: - ETA: 15:37 - loss: 1.0788 - accuracy: - ETA: 14:59 - loss: 1.0646 - accuracy: 0.67 - ETA: 14:50 - loss: 1.0597 - accuracy: 0 - ETA: 14:31 - - ETA: 12:10 - loss: 0.9 - ETA: 10:51 - loss: 0. - ETA: 9:44 - loss: 0.9264 - accura - ETA: 9:31 - loss: 0.9185 - accuracy: 0. - ETA: 9:25 - loss: 0.9166 - accuracy: 0. - ETA: 9:19 - loss: 0.9135 - accuracy - ETA: 9:08 - loss: 0.9084 - accuracy:  - ETA: 8:59 - loss: 0 - ETA: 8:28 - loss: 0.8906 - accu - ETA: 8:12 - loss: 0.8847  - ETA: 7:48 - loss: 0.8778 - accuracy: 0.74 - ETA: 7:45 - loss: 0.8767 - accuracy: 0.74 - ETA: 7:43 - loss: - ETA: 6:14 - loss: 0.8441 - accuracy: 0.75 - ETA: 6:12 - loss: 0.8439 - accura - ETA: 6:02 - loss: 0.8394 - accuracy - ETA: 5:53 - loss: 0.8361 - accuracy: 0. - ETA: 5:49 - loss: 0.8343 - accu - ETA: 5:36 - loss: 0.8285  - ETA: 5:17 - loss: 0.8235 - accuracy:  - ETA: 5:11 - loss: 0.8 - ETA: 4:49 - l - ETA: 4:17 - loss: 0.8011 - accuracy: 0.76 - ETA: 4:15 - loss: 0.800 - ETA: 3:14 - loss: 0.7 - ETA: 2:53 - loss: 0.7703 - accu - ETA: 2:43 - loss: 0.7669 - accuracy - ETA: 2:36 - los - ETA: 2:11 - loss: 0.7588 - accuracy:  - ETA: 2:06 - loss: 0.7560  - ETA: 1:50 - loss: 0.749 - ETA: 1:33 - loss: 0.7438 - accu - ETA: 1:23 - loss: 0.7403 - accuracy:  - ETA: 1 - ETA: 35s - loss: 0.7231 - accuracy: 0.78 - ETA: 31s - loss: 0.7220 - accuracy: 0.78 - ETA: 28s - loss: 0.7213 - accura - ETA: 12s - loss: 0.7152 - ac\n",
      "Epoch 2/2\n",
      "18000/18000 [==============================] - 570s 32ms/sample - loss: 0.3912 - accuracy: 0.8843 10:12 - loss: 0.442 - ETA: 11:29 - loss: 0.4185 - accuracy:  - ETA: 11:29 - loss - ETA: 10:04 - loss: 0.4185 - accuracy: 0.878 - ETA: 10:05 - loss: 0.4188 - accuracy: 0.877 - - ETA: 9:24 - loss: 0.4057 -  - ETA: 9:04 - loss: 0.4055 - accu - ETA: 4: - ETA: 4:15 - loss: 0.4011 - ac - ETA: 4:08 - loss: 0.3999 - ac - ETA: 4:02 - loss: 0.4007 - accura - ETA:  - ETA: 3:36 - loss: 0.4004 - accuracy: 0.88 - ETA: 3:34 - loss: 0.4008 - accuracy - ETA: 3:33 - loss: 0.4 - ETA: 3:22 - loss: 0.3994 -  - ETA: 3:16 - loss: 0.3982 - ac - ETA: 3:12 - loss: 0.3971 - accuracy - ETA: 3:08 - loss: 0.3971 - accu - ETA: 3:02 - loss: 0.3975 - accuracy: 0. - ETA: 3:02 - ETA: 2:45 - loss: 0.3970 - ac - ETA: 2:38 - loss: 0.3969 -  - E - ETA: 1:22 - loss: 0.3937 -  - ETA: 1:14 - loss: 0.3933 - accura - ETA: 1:09 - loss: 0.3925 - accu - ETA: 1:04 - loss: 0.3918 - accuracy: 0.88 - ETA: 1:03 - loss: 0.3919 - accuracy: 0.88 - ETA: 1:02 - loss: 0.3918 - accuracy: 0. - ETA: 1:00 - loss: 0.3921 - accurac - ETA: 53s - loss: 0.3921 - accuracy: 0.88 - ETA: 51s - loss: 0.3927 - accuracy: 0.88 - ETA: 49s - loss: 0.3929 - accuracy: 0.8 - ETA: 46s - loss: 0.3935 - accuracy:  - ETA: 40s - loss: 0.3939 - accuracy:  - ETA: 34s - loss: 0.3927 - accuracy: 0.88 - ETA: 32s - loss: 0. - ETA: 9s - loss: 0.3924 - accuracy: 0.883 - ETA: 8s - loss: 0.3928 - accuracy - ETA: 4s - loss: 0.3920 - accuracy: 0. - ETA: 2s - loss: 0.3914 - accuracy: \n",
      "CLIENT::[10.0.0.3]::Training model.\n",
      "Train on 12000 samples\n",
      "Epoch 1/2\n",
      "12000/12000 [==============================] - 481s 40ms/sample - loss: 0.8553 - accuracy: 0.7525A: 1:05:23 - loss: 2.2213 - ac - ETA: 34:51 - loss: 2.0747 - accuracy: 0.3 - ETA: 32:05 - loss: 2.0559 - accuracy: 0.313 - ETA: 31:11 - loss: 2.0437 - accuracy: 0. - ETA: 28:06 - loss: 2.0012 - accu - ETA: 21:24 - loss: 1.8934 - ETA: 15:26 - loss: 1.7040 - a - ETA: 12:39 - loss: 1.5926 - accuracy: 0. - ETA: 12: - ETA: 7:33 - loss: 1.2907 - accura - ETA: 6:04 - loss: 1.2001 - accuracy: 0. - ETA: 5:59 - loss: 1.1948 - accu - ETA: 4:03 - loss: 1.0749 - accuracy: 0.68 - ETA: 4:02 - loss: 1.0740  - ETA: 3:45 - loss: 1.0606 - accuracy: 0.69 - ETA: 3:43 - loss: 1.0588 - accuracy:  - ETA: 3:37 - loss: 1.0520 -  - ETA: 3:24 - loss: 1.0356 - accu - ETA: 2:33 - loss: 0.9798 - accuracy:  - ETA: 1:16 - loss: 0.9149 - accuracy - ETA: 1 - ETA: 30s - l\n",
      "Epoch 2/2\n",
      "12000/12000 [==============================] - 334s 28ms/sample - loss: 0.4387 - accuracy: 0.8728:46 - loss: 0 - ETA: 4:23 - loss: 0.4903 - ac - ETA: 4:27 - loss: 0.4911 - accuracy: 0. - ETA: 4:28 - loss: 0.4940 - accu - ETA: 4:21 - loss: 0.4907 - accuracy: 0.85 - ETA: 4:22 - loss: 0.4907 - accuracy:  - ETA: 4:19 - loss: 0.4852 - accura - ETA: 4:12 - loss: 0 - ETA: 2:48 - los - ETA: 1:12 -  - ETA: 58s - loss: 0. - ETA: 38s - loss: 0.4424 - accuracy:  - ETA: 33s - loss: 0.4419 - - ETA: 18s - loss: 0.4402 - accuracy: 0.872 - ETA: 17s - loss: 0.4404 - accuracy: 0.872 - ETA: 16s - loss: 0.4397 - accu - ETA: 8s - loss: 0.4392 \n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Create a graph\n",
    "graph = {}\n",
    "graph[\"10.0.0.1\"] = [\"10.0.0.2\", \"10.0.0.3\"]\n",
    "graph[\"10.0.0.2\"] = [\"10.0.0.1\", \"10.0.0.3\"]\n",
    "graph[\"10.0.0.3\"] = [\"10.0.0.1\", \"10.0.0.2\"]\n",
    "print(\"Created network graph.\")\n",
    "\n",
    "# Create nodes for the virtual network\n",
    "ipRegistry = {}\n",
    "for addr in graph.keys():\n",
    "    newNode = DummyNet(addr, graph[addr])\n",
    "    ipRegistry[addr] = newNode\n",
    "# Build network (decentralized)\n",
    "for addr in graph.keys():\n",
    "    ipRegistry[addr].init_network(ipRegistry)\n",
    "print(\"Registered nodes in network graph.\")\n",
    "\n",
    "# Create Incubator with data ratios\n",
    "MI = ModelIncubator([0.5, 0.3, 0.2])\n",
    "\n",
    "# Create clients\n",
    "clientDict = {}\n",
    "ind = 0\n",
    "for ip in ipRegistry.keys():\n",
    "    print(\"Creating client \", ind, \" with IP \", ip, \".\")\n",
    "    clientDict[ip] = Client(netNode=ipRegistry[ip], model=Model(data=MI.data_shares[ind]))\n",
    "    ind += 1\n",
    "print(\"Clients created and linked to nodes.\")\n",
    "\n",
    "# clientDict[\"10.0.0.1\"].transmit(str(time.time()), \"10.0.0.2\")\n",
    "# time.sleep(2.5)\n",
    "# clientDict[\"10.0.0.2\"].transmit(str(time.time()), \"10.0.0.3\")\n",
    "# time.sleep(2.5)\n",
    "\n",
    "# print(\"Begin experiment.\")\n",
    "# for i in range(10):\n",
    "#     secrets.choice(list(clientDict.values())).transmit_model()\n",
    "#     time.sleep(1)\n",
    "\n",
    "# Start execution\n",
    "console = Console(clientDict)\n",
    "console.run()\n",
    "\n",
    "print(\"Ending experiment.\")\n",
    "# Kill all nodes\n",
    "for addr in graph.keys():\n",
    "    ipRegistry[addr].kill()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
